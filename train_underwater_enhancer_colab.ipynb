{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Underwater Image Enhancement with Autoencoder - Google Drive Edition\nThis notebook trains an autoencoder model to enhance underwater GoPro images, matching manually edited quality.\n\n## üöÄ Quick Start\n1. **Run in Google Colab** with GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)\n2. **Mount Google Drive** (you'll be prompted once)\n3. **First run**: Dataset downloads automatically to Drive (~15 min, one-time only)\n4. **Subsequent runs**: Loads from Drive in seconds!\n\n## üìÅ Google Drive Structure\nAfter first run, your Drive will contain:\n```\nMyDrive/\n‚îî‚îÄ‚îÄ underwater_enhancement/\n    ‚îú‚îÄ‚îÄ dataset/           # Cached dataset (loads in seconds)\n    ‚îú‚îÄ‚îÄ models/            # Trained models\n    ‚îî‚îÄ‚îÄ checkpoints/       # Training checkpoints (resume capability)\n```\n\n## ‚ú® Features\n- **Persistent storage**: Everything saves to Google Drive\n- **Resume training**: Automatically continues from last checkpoint\n- **Fast loading**: Dataset cached after first download\n- **No re-downloads**: Access your data and models anytime"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'GPU Available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU available, using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q datasets pillow torch torchvision tqdm matplotlib tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Mount Google Drive and Setup Paths"
  },
  {
   "cell_type": "markdown",
   "source": "### 2a. Load Dataset from Google Drive (Fast after first run)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Mount Google Drive\nfrom google.colab import drive\nimport os\nimport pickle\nfrom pathlib import Path\n\ndrive.mount('/content/drive')\n\n# Create directory structure in Google Drive\nDRIVE_BASE = Path('/content/drive/MyDrive/underwater_enhancement')\nDATASET_PATH = DRIVE_BASE / 'dataset'\nMODELS_PATH = DRIVE_BASE / 'models'\nCHECKPOINT_PATH = DRIVE_BASE / 'checkpoints'\n\n# Create directories if they don't exist\nDRIVE_BASE.mkdir(exist_ok=True)\nDATASET_PATH.mkdir(exist_ok=True)\nMODELS_PATH.mkdir(exist_ok=True)\nCHECKPOINT_PATH.mkdir(exist_ok=True)\n\nprint(f\"‚úì Google Drive mounted\")\nprint(f\"‚úì Project directory: {DRIVE_BASE}\")\nprint(f\"‚úì Dataset will be stored at: {DATASET_PATH}\")\nprint(f\"‚úì Models will be saved at: {MODELS_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load or download dataset\nDATASET_FILE = DATASET_PATH / 'underwater_dataset.pkl'\nDATASET_PROCESSED = DATASET_PATH / 'processed'\n\nif DATASET_FILE.exists():\n    # Load from Google Drive (fast)\n    print(\"Loading dataset from Google Drive...\")\n    with open(DATASET_FILE, 'rb') as f:\n        dataset = pickle.load(f)\n    print(f\"‚úì Loaded {len(dataset)} samples from Google Drive (fast load)\")\n    \nelif DATASET_PROCESSED.exists():\n    # Load processed dataset from disk format\n    print(\"Loading processed dataset from Google Drive...\")\n    from datasets import load_from_disk\n    dataset = load_from_disk(str(DATASET_PROCESSED))\n    print(f\"‚úì Loaded {len(dataset)} samples from processed format\")\n    \nelse:\n    # First time - download from Hugging Face and save to Drive\n    print(\"First run detected - downloading dataset from Hugging Face...\")\n    print(\"This will take a few minutes but only needs to be done once.\")\n    \n    # Option 1: Load full dataset (recommended for production)\n    dataset = load_dataset(\"keenanj/testing-underwater\", split=\"train\")\n    \n    # Option 2: Load smaller subset for testing (uncomment if needed)\n    # dataset = load_dataset(\"keenanj/testing-underwater\", split=\"train[:30%]\")  # 30% for testing\n    \n    print(f\"‚úì Downloaded {len(dataset)} samples\")\n    \n    # Save to Google Drive for next time\n    print(\"Saving dataset to Google Drive for faster future loads...\")\n    \n    # Save as pickle for fastest loading\n    with open(DATASET_FILE, 'wb') as f:\n        pickle.dump(dataset, f)\n    \n    # Also save in HuggingFace format\n    dataset.save_to_disk(str(DATASET_PROCESSED))\n    \n    print(\"‚úì Dataset saved to Google Drive!\")\n    print(\"‚úì Next time, loading will be much faster (10-30 seconds)\")\n\nprint(f\"\\\\nDataset ready with {len(dataset)} samples\")\nprint(f\"Dataset features: {dataset.features if hasattr(dataset, 'features') else 'N/A'}\")"
  },
  {
   "cell_type": "code",
   "source": "# Explore the dataset structure\nsample = dataset[0]\nprint(\"Sample keys:\", sample.keys() if hasattr(sample, 'keys') else type(sample))\n\n# Display a sample pair\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n# Handle different dataset formats\nif isinstance(sample, dict):\n    input_img = sample.get('input', sample.get('image', None))\n    output_img = sample.get('output', sample.get('target', None))\nelse:\n    print(\"Dataset format not recognized, skipping visualization\")\n    input_img = None\n    output_img = None\n\nif input_img is not None:\n    axes[0].imshow(input_img)\n    axes[0].set_title('Input (GPR/RAW)')\n    axes[0].axis('off')\n\nif output_img is not None:\n    axes[1].imshow(output_img)\n    axes[1].set_title('Target (Manually Edited JPEG)')\n    axes[1].axis('off')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset structure\n",
    "sample = dataset[0]\n",
    "print(\"Sample keys:\", sample.keys())\n",
    "\n",
    "# Display a sample pair\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "if 'input' in sample:\n",
    "    axes[0].imshow(sample['input'])\n",
    "    axes[0].set_title('Input (GPR/RAW)')\n",
    "    axes[0].axis('off')\n",
    "if 'output' in sample:\n",
    "    axes[1].imshow(sample['output'])\n",
    "    axes[1].set_title('Target (Manually Edited JPEG)')\n",
    "    axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderwaterDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, image_size=512, augment=False):\n",
    "        self.dataset = hf_dataset\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Define transforms\n",
    "        transform_list = [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        \n",
    "        if augment:\n",
    "            # Add augmentation for training\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=10),\n",
    "                *transform_list\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        \n",
    "        # Load images\n",
    "        input_img = sample['input'].convert('RGB') if 'input' in sample else sample['image'].convert('RGB')\n",
    "        target_img = sample['output'].convert('RGB') if 'output' in sample else sample['target'].convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.augment:\n",
    "            # Apply same random transform to both images\n",
    "            seed = torch.randint(0, 2**32, (1,)).item()\n",
    "            torch.manual_seed(seed)\n",
    "            input_img = self.transform(input_img)\n",
    "            torch.manual_seed(seed)\n",
    "            target_img = self.transform(target_img)\n",
    "        else:\n",
    "            input_img = self.transform(input_img)\n",
    "            target_img = self.transform(target_img)\n",
    "        \n",
    "        return input_img, target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Create indices for splitting\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = UnderwaterDataset(dataset.select(train_indices), image_size=256, augment=True)\n",
    "val_dataset = UnderwaterDataset(dataset.select(val_indices), image_size=256, augment=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create optimized data loaders\nbatch_size = 16  # Adjust based on GPU memory\n\n# Optimize DataLoader settings for Colab\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=2,  # Colab typically has 2 CPU cores\n    pin_memory=True,  # Faster GPU transfer\n    prefetch_factor=2,  # Prefetch batches\n    persistent_workers=True  # Keep workers alive between epochs\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=2,\n    pin_memory=True,\n    prefetch_factor=2,\n    persistent_workers=True\n)\n\nprint(f\"Batches per epoch: {len(train_loader)}\")\nprint(f\"DataLoader optimized with prefetching and persistent workers\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define U-Net Based Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double Convolution Block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNetAutoencoder(nn.Module):\n",
    "    \"\"\"U-Net based autoencoder for image enhancement\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=3):\n",
    "        super(UNetAutoencoder, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = UNetAutoencoder(n_channels=3, n_classes=3).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined loss function for image enhancement\"\"\"\n",
    "    def __init__(self, alpha=0.8, beta=0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        l1 = self.l1_loss(pred, target)\n",
    "        mse = self.mse_loss(pred, target)\n",
    "        return self.alpha * l1 + self.beta * mse\n",
    "\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    mse = torch.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = CombinedLoss(alpha=0.8, beta=0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training history\ntrain_losses = []\nval_losses = []\ntrain_psnrs = []\nval_psnrs = []\n\n# Resume from checkpoint if exists\nCHECKPOINT_FILE = CHECKPOINT_PATH / 'latest_checkpoint.pth'\nstart_epoch = 0\n\nif CHECKPOINT_FILE.exists():\n    print(\"Found checkpoint, resuming training...\")\n    checkpoint = torch.load(CHECKPOINT_FILE)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    train_losses = checkpoint.get('train_losses', [])\n    val_losses = checkpoint.get('val_losses', [])\n    train_psnrs = checkpoint.get('train_psnrs', [])\n    val_psnrs = checkpoint.get('val_psnrs', [])\n    best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n    print(f\"Resuming from epoch {start_epoch}\")\n\n# Training loop\nfor epoch in range(start_epoch, num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 50)\n    \n    # Train\n    train_loss, train_psnr = train_epoch(model, train_loader, criterion, optimizer, device)\n    train_losses.append(train_loss)\n    train_psnrs.append(train_psnr)\n    \n    # Validate\n    val_loss, val_psnr = validate_epoch(model, val_loader, criterion, device)\n    val_losses.append(val_loss)\n    val_psnrs.append(val_psnr)\n    \n    # Update learning rate\n    scheduler.step(val_loss)\n    \n    print(f\"Train Loss: {train_loss:.4f}, Train PSNR: {train_psnr:.2f} dB\")\n    print(f\"Val Loss: {val_loss:.4f}, Val PSNR: {val_psnr:.2f} dB\")\n    \n    # Save checkpoint to Google Drive\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'val_loss': val_loss,\n        'val_psnr': val_psnr,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'train_psnrs': train_psnrs,\n        'val_psnrs': val_psnrs,\n        'best_val_loss': best_val_loss\n    }\n    \n    # Save latest checkpoint\n    torch.save(checkpoint, CHECKPOINT_FILE)\n    \n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_model_path = MODELS_PATH / 'best_underwater_enhancer.pth'\n        torch.save(checkpoint, best_model_path)\n        print(f\"‚úì Saved best model to Google Drive: {best_model_path}\")\n        patience_counter = 0\n    else:\n        patience_counter += 1\n    \n    # Save periodic checkpoint (every 5 epochs)\n    if (epoch + 1) % 5 == 0:\n        periodic_checkpoint = CHECKPOINT_PATH / f'checkpoint_epoch_{epoch+1}.pth'\n        torch.save(checkpoint, periodic_checkpoint)\n        print(f\"‚úì Saved periodic checkpoint to: {periodic_checkpoint}\")\n    \n    # Early stopping\n    if patience_counter >= patience:\n        print(f\"Early stopping triggered after {epoch+1} epochs\")\n        break\n\nprint(\"\\n‚úì Training complete!\")\nprint(f\"‚úì All models and checkpoints saved to Google Drive: {DRIVE_BASE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_psnrs = []\n",
    "val_psnrs = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_psnr = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_psnrs.append(train_psnr)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_psnr = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_psnrs.append(val_psnr)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train PSNR: {train_psnr:.2f} dB\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val PSNR: {val_psnr:.2f} dB\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_psnr': val_psnr,\n",
    "        }, 'best_underwater_enhancer.pth')\n",
    "        print(\"‚úì Saved best model\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(val_losses, label='Val Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# PSNR plot\n",
    "ax2.plot(train_psnrs, label='Train PSNR', color='blue')\n",
    "ax2.plot(val_psnrs, label='Val PSNR', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('PSNR (dB)')\n",
    "ax2.set_title('Training and Validation PSNR')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Load best model from Google Drive\nbest_model_path = MODELS_PATH / 'best_underwater_enhancer.pth'\n\nif best_model_path.exists():\n    checkpoint = torch.load(best_model_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"‚úì Loaded best model from Google Drive\")\n    print(f\"  Epoch: {checkpoint['epoch']+1}\")\n    print(f\"  Best Val Loss: {checkpoint['val_loss']:.4f}\")\n    print(f\"  Best Val PSNR: {checkpoint['val_psnr']:.2f} dB\")\nelse:\n    print(\"No saved model found in Google Drive\")\n    print(\"Please train the model first\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('best_underwater_enhancer.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"Best Val PSNR: {checkpoint['val_psnr']:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, dataloader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(dataloader):\n",
    "            if idx >= num_samples:\n",
    "                break\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Take first image from batch\n",
    "            input_img = inputs[0].cpu().permute(1, 2, 0).numpy()\n",
    "            target_img = targets[0].cpu().permute(1, 2, 0).numpy()\n",
    "            output_img = outputs[0].cpu().permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Display\n",
    "            axes[idx, 0].imshow(input_img)\n",
    "            axes[idx, 0].set_title('Input (Raw)')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(output_img)\n",
    "            axes[idx, 1].set_title('Model Output')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            axes[idx, 2].imshow(target_img)\n",
    "            axes[idx, 2].set_title('Target (Manual Edit)')\n",
    "            axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "visualize_results(model, val_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Save final model to Google Drive\nfinal_model_path = MODELS_PATH / 'underwater_enhancer_final.pth'\n\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'model_config': {\n        'n_channels': 3,\n        'n_classes': 3,\n        'image_size': 256\n    },\n    'training_history': {\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'train_psnrs': train_psnrs,\n        'val_psnrs': val_psnrs\n    }\n}, final_model_path)\n\nprint(f\"‚úì Model saved to Google Drive: {final_model_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export to ONNX for deployment (saved to Google Drive)\nonnx_path = MODELS_PATH / 'underwater_enhancer.onnx'\n\ndummy_input = torch.randn(1, 3, 256, 256).to(device)\ntorch.onnx.export(\n    model,\n    dummy_input,\n    str(onnx_path),\n    export_params=True,\n    opset_version=11,\n    do_constant_folding=True,\n    input_names=['input'],\n    output_names=['output'],\n    dynamic_axes={'input': {0: 'batch_size'},\n                  'output': {0: 'batch_size'}}\n)\nprint(f\"‚úì Model exported to ONNX format: {onnx_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX for deployment (optional)\n",
    "dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"underwater_enhancer.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'},\n",
    "                  'output': {0: 'batch_size'}}\n",
    ")\n",
    "print(\"Model exported to ONNX format as 'underwater_enhancer.onnx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Inference Function for New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(model, image_path, device, save_path=None):\n",
    "    \"\"\"\n",
    "    Enhance a single underwater image using the trained model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_size = image.size\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate enhanced image\n",
    "    with torch.no_grad():\n",
    "        enhanced_tensor = model(input_tensor)\n",
    "    \n",
    "    # Convert back to PIL image\n",
    "    enhanced_image = transforms.ToPILImage()(enhanced_tensor.squeeze(0).cpu())\n",
    "    enhanced_image = enhanced_image.resize(original_size, Image.LANCZOS)\n",
    "    \n",
    "    # Save if path provided\n",
    "    if save_path:\n",
    "        enhanced_image.save(save_path)\n",
    "        print(f\"Enhanced image saved to {save_path}\")\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "# Example usage (uncomment and modify path when using):\n",
    "# enhanced = enhance_image(model, 'path_to_raw_image.jpg', device, 'enhanced_output.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Models are already saved to Google Drive!\nprint(\"‚úÖ All models are saved in your Google Drive at:\")\nprint(f\"   {MODELS_PATH}\")\nprint(\"\\nSaved files:\")\nprint(f\"  ‚Ä¢ best_underwater_enhancer.pth - Best model from training\")\nprint(f\"  ‚Ä¢ underwater_enhancer_final.pth - Final model with full config\")\nprint(f\"  ‚Ä¢ underwater_enhancer.onnx - ONNX format for deployment\")\nprint(\"\\nYou can access these files anytime through Google Drive!\")\nprint(\"No need to download - they persist between Colab sessions.\")\n\n# Optional: Download to local machine if needed\ndownload_locally = False  # Change to True if you want to download\n\nif download_locally:\n    from google.colab import files\n    print(\"\\nDownloading model files to your local machine...\")\n    files.download(str(MODELS_PATH / 'best_underwater_enhancer.pth'))\n    files.download(str(MODELS_PATH / 'underwater_enhancer_final.pth'))\n    files.download(str(MODELS_PATH / 'underwater_enhancer.onnx'))\n    print(\"‚úì Download complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model files from Colab\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading model files...\")\n",
    "files.download('best_underwater_enhancer.pth')\n",
    "files.download('underwater_enhancer_final.pth')\n",
    "files.download('underwater_enhancer.onnx')\n",
    "print(\"Download complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}